{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from jupyterthemes import jtplot\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import h2o\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "jtplot.style(theme='monokai', context='talk', fscale=1.4, ticks=True, grid=False, figsize=(6, 4.5), gridlines='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('churn.csv')\n",
    "#churn_h20 = h2o.import_file(path='churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4250 entries, 0 to 4249\n",
      "Data columns (total 20 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   state                          4250 non-null   object \n",
      " 1   account_length                 4250 non-null   int64  \n",
      " 2   area_code                      4250 non-null   object \n",
      " 3   international_plan             4250 non-null   object \n",
      " 4   voice_mail_plan                4250 non-null   object \n",
      " 5   number_vmail_messages          4250 non-null   int64  \n",
      " 6   total_day_minutes              4250 non-null   float64\n",
      " 7   total_day_calls                4250 non-null   int64  \n",
      " 8   total_day_charge               4250 non-null   float64\n",
      " 9   total_eve_minutes              4250 non-null   float64\n",
      " 10  total_eve_calls                4250 non-null   int64  \n",
      " 11  total_eve_charge               4250 non-null   float64\n",
      " 12  total_night_minutes            4250 non-null   float64\n",
      " 13  total_night_calls              4250 non-null   int64  \n",
      " 14  total_night_charge             4250 non-null   float64\n",
      " 15  total_intl_minutes             4250 non-null   float64\n",
      " 16  total_intl_calls               4250 non-null   int64  \n",
      " 17  total_intl_charge              4250 non-null   float64\n",
      " 18  number_customer_service_calls  4250 non-null   int64  \n",
      " 19  churn                          4250 non-null   object \n",
      "dtypes: float64(8), int64(7), object(5)\n",
      "memory usage: 664.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.7, validate_percent=.15, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train, validate, test = train_validate_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2975\n",
      "validate 637\n",
      "test 638\n"
     ]
    }
   ],
   "source": [
    "print('train', len(train))\n",
    "print('validate', len(validate))\n",
    "print('test', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 5, 10, 20, 50, 100]\n",
    "vector1 = np.array(list1)\n",
    "\n",
    "array1 = np.arange(0.3, 1, 0.05)\n",
    "array2 = np.arange(0.3, 1, 0.05)\n",
    "array3 = np.arange(0.3,1,0.05)\n",
    "array4 = np.arange(0.1, 5.1, 0.5)\n",
    "tf_list = [True, False]\n",
    "histo_type = [\"UniformAdaptive\", \"QuantilesGlobal\", \"RoundRobin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''gradient_boosted_hp_grid = [ \n",
    "  max_depth = list(range(1,20)), \n",
    "  min_rows = vector1, \n",
    "  sample_rate = array1,\n",
    "  col_sample_rate = array2,\n",
    "  col_sample_rate_per_tree = array3,\n",
    "  balance_classes = tf_list,\n",
    "  max_after_balance_size = array4,\n",
    "  histogram_type = histo_type\n",
    "]'''\n",
    "\n",
    "max_depth = list(range(1,20))\n",
    "min_rows = vector1\n",
    "sample_rate = array1\n",
    "col_sample_rate = array2\n",
    "col_sample_rate_per_tree = array3\n",
    "balance_classes = tf_list\n",
    "max_after_balance_size = array4\n",
    "histogram_type = histo_type\n",
    "\n",
    "gradient_boosted_hp_grid = [max_depth, min_rows, sample_rate, col_sample_rate, col_sample_rate_per_tree, balance_classes,\n",
    "                            max_after_balance_size, histogram_type] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"RandomDiscrete\"\n",
    "max_runtime_secs = 120\n",
    "max_models = 100\n",
    "stopping_metric = \"AUTO\"\n",
    "stopping_tolerance = 0.001\n",
    "stopping_rounds = 5\n",
    "seed = 123456\n",
    "\n",
    "gradient_boosted_hp_strategy = [\n",
    "  strategy, \n",
    "  max_runtime_secs,\n",
    "  max_models,\n",
    "  stopping_metric, \n",
    "  stopping_tolerance, \n",
    "  stopping_rounds, \n",
    "  seed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gradient_boosted_model_grid = H2OGridSearch(\\n  grid_id = \"gradient_boosted_churn\", \\n  sort_by = \"f1\",\\n  decreasing = True\\n)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''gradient_boosted_model_grid = H2OGridSearch(\n",
    "  grid_id = \"gradient_boosted_churn\", \n",
    "  sort_by = \"f1\",\n",
    "  decreasing = True\n",
    ")'''\n",
    "# https://www.kaggle.com/code/gpreda/hyperparameter-tuning-using-gridsearch-with-h2o/notebook"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
